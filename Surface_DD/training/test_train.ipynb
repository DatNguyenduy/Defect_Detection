{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DuyDat\\anaconda3\\envs\\pythonENV\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "from dataset.defect_dataset import DefectDataset\n",
    "from model.models import UNet\n",
    "from training.train_model import training_model\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "results_path = \"test_results\"\n",
    "unet_config = {\n",
    "        \"encChannels\": [1,8,16,32,64],\n",
    "        \"decChannels\": [64,32,16,8],\n",
    "        \"retainDim\": True,\n",
    "        \"input_image_height\":256,\n",
    "        \"input_image_width\":128\n",
    "    }\n",
    "\n",
    "data_path = \"D:\\\\APPLY_JOB_2023\\\\Data\\\\KolektorSDD-boxes\"\n",
    "\n",
    "\n",
    "image_size = [256,128]\n",
    "\n",
    "batch_size = 16\n",
    "num_workers:int = 0\n",
    "learningrate: int = 1e-3\n",
    "weight_decay: float = 1e-5\n",
    "nb_epochs: int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] found 319 examples in the SOURCE training set...\n",
      "[INFO] found 80 examples in the source validationset set...\n",
      "[INFO] device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load or download source dataset\n",
    "tr_forms = transforms.ToTensor()\n",
    "source_dl = DefectDataset(data_dir=data_path,img_size=image_size)\n",
    "\n",
    "#source_dl = SourceData(**data_config,train_transformer(**data_config))\n",
    "\n",
    "# Split source into training, validation and test set\n",
    "trainingset = Subset(source_dl,indices=np.arange(int(len(source_dl) * (4 / 5))))\n",
    "validationset = Subset(source_dl, indices=np.arange(int(len(source_dl) * (4 / 5)), len(source_dl)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"[INFO] found {len(trainingset)} examples in the SOURCE training set...\")\n",
    "\n",
    "print(f\"[INFO] found {len(validationset)} examples in the source validationset set...\")\n",
    "\n",
    "# Create datasets and dataloaders \n",
    "trainloader = DataLoader(trainingset, batch_size, shuffle=False, num_workers=num_workers)\n",
    "valloader = DataLoader(validationset, batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "\n",
    "# Create Network\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] device is {device}\")\n",
    "model_Seg = UNet(**unet_config).to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Get loss function\n",
    "criterion_seg = nn.BCELoss()\n",
    "criterion_domain = BCEWithLogitsLoss()\n",
    "jaccard = BinaryJaccardIndex(threshold=0.5)\n",
    "# Get adam optimizer\n",
    "optimizer_seg = torch.optim.Adam(\n",
    "        model_Seg.parameters(),\n",
    "        lr=learningrate,\n",
    "        weight_decay=weight_decay, betas=(0.5, 0.99)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\APPLY_JOB_2023\\Defect_Detection\\Surface_DD\\training\\..\\dataset\\defect_dataset.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  return (torch.tensor([img_array]),torch.tensor([label_array]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "torch.Size([16, 1, 256, 128])\n",
      "torch.Size([16, 1, 256, 128])\n"
     ]
    }
   ],
   "source": [
    "for batch,(X,y) in enumerate(trainloader):\n",
    "    print(\"batch\",batch)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "from torchmetrics import JaccardIndex\n",
    "jaccard_index = JaccardIndex(task='binary',num_classes=2)\n",
    "target = tensor([[0, 1, 0], [1, 0, 1]])\n",
    "preds = tensor([[0.11, 0.22, 0.84], [0.73, 0.33, 0.92]])\n",
    "jaccard_index(preds, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 256, 128])\n",
      "torch.Size([16, 1, 256, 128])\n"
     ]
    }
   ],
   "source": [
    "epoch  = 0\n",
    "X,y = X.float().to(device),y.to(device)\n",
    "\n",
    "optimizer_seg.zero_grad()\n",
    "\n",
    "domain_label_src = torch.ones((len(X),1)).to(device)\n",
    "\n",
    "\n",
    "# Segmentation loss:\n",
    "pred = model_Seg(X)\n",
    "# seg_loss = criterion_seg(pred,y)\n",
    "# IOU score:\n",
    "# iou_score = jaccard_index(pred,y)\n",
    "pred_class = pred.argmax(dim=1)\n",
    "# iou_score = jaccard(src_pred_class,src_y)\n",
    "print(pred_class.shape)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1244, 0.1244, 0.1244, 0.1244, 0.1229, 0.1229, 0.1229, 0.1229, 0.1226,\n",
       "         0.1226],\n",
       "        [0.1244, 0.1244, 0.1244, 0.1244, 0.1229, 0.1229, 0.1229, 0.1229, 0.1226,\n",
       "         0.1226],\n",
       "        [0.1234, 0.1234, 0.1234, 0.1234, 0.1231, 0.1231, 0.1231, 0.1231, 0.1229,\n",
       "         0.1229],\n",
       "        [0.1234, 0.1234, 0.1234, 0.1234, 0.1231, 0.1231, 0.1231, 0.1231, 0.1229,\n",
       "         0.1229],\n",
       "        [0.1255, 0.1255, 0.1255, 0.1255, 0.1244, 0.1244, 0.1244, 0.1244, 0.1235,\n",
       "         0.1235],\n",
       "        [0.1233, 0.1233, 0.1233, 0.1233, 0.1254, 0.1254, 0.1254, 0.1254, 0.1233,\n",
       "         0.1233],\n",
       "        [0.1233, 0.1233, 0.1233, 0.1233, 0.1254, 0.1254, 0.1254, 0.1254, 0.1233,\n",
       "         0.1233],\n",
       "        [0.1247, 0.1247, 0.1247, 0.1247, 0.1256, 0.1256, 0.1256, 0.1256, 0.1255,\n",
       "         0.1255],\n",
       "        [0.1242, 0.1242, 0.1242, 0.1242, 0.1265, 0.1265, 0.1265, 0.1265, 0.1240,\n",
       "         0.1240],\n",
       "        [0.1242, 0.1242, 0.1242, 0.1242, 0.1265, 0.1265, 0.1265, 0.1265, 0.1240,\n",
       "         0.1240]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1,0,:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[[0.2,0.9],[0.1,0.2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.argmax(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class[1,:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1367090484.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(seg_loss.)\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(seg_loss.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "dataloader = source_valloader\n",
    "is_bar_progress = False\n",
    "jaccard = JaccardIndex(task =\"multiclass\",num_classes=nb_classes).to(device=device)\n",
    "if is_bar_progress:\n",
    "    update_progress_bar = tqdm(total=len(dataloader),desc=f\"Evaluating: scoring: {np.nan:7.5f};iou scoring: {np.nan:7.5f}\",position=0)\n",
    "model_Seg.to(device)\n",
    "model_Seg.eval()\n",
    "mean_score = 0\n",
    "count_batch = 0\n",
    "mean_iou_score = 0\n",
    "with torch.no_grad():\n",
    "    for _,(X,y,y_lables) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred,_ = model_Seg(X)\n",
    "        iou_score = jaccard(y_pred,y)\n",
    "        mean_iou_score =(mean_iou_score*count_batch + iou_score)/(count_batch+1)\n",
    "        mean_score = (mean_score*count_batch + criterion_seg(y_pred,y))/(count_batch+1)\n",
    "        count_batch += 1\n",
    "        if is_bar_progress:\n",
    "            update_progress_bar.set_description(f\"Evaluating: scoring: {mean_score:7.5f}; iou scoring: {mean_iou_score:7.5f}\", refresh=True)\n",
    "            update_progress_bar.update()\n",
    "    if is_bar_progress:\n",
    "        update_progress_bar.close()\n",
    "model_Seg.train()\n",
    "print( mean_score,mean_iou_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
